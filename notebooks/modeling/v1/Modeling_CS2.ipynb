{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Modeling_CS2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2RSzdW901xCt"
      },
      "source": [
        "# Image To Image Translation - Self Case Study 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PCl9HOVG8drD"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import Model, Input\n",
        "from tensorflow.keras.initializers import RandomNormal\n",
        "from tensorflow.keras.layers import Conv2D, Conv2DTranspose, BatchNormalization, LeakyReLU, Dropout, ReLU, Concatenate, Activation,ZeroPadding2D\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bjwowsd2YDQm"
      },
      "source": [
        "## Loading Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJ1INTnqYFKa"
      },
      "source": [
        "image_data = np.load('/content/drive/MyDrive/Case Study 2/data/modeling/image_data.npz')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8a5tPWyxYNOg"
      },
      "source": [
        "train_sat_images = image_data['train_sat_images']\n",
        "train_map_images = image_data['train_map_images']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sHbsRfEf13nS"
      },
      "source": [
        "## Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lfmjxzCP15gb"
      },
      "source": [
        "### Basic Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0uVsVpNV2DA9"
      },
      "source": [
        "For basic model, we'll be implementing cGAN (without L1 regularization).\n",
        "<br>\n",
        "Our model consists of 2 parts:\n",
        "- Generator\n",
        "- Discriminator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6DaVoqe7bH0s"
      },
      "source": [
        "#### Defining Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bkOZwrkVHrjo"
      },
      "source": [
        "#https://machinelearningmastery.com/how-to-develop-a-pix2pix-gan-for-image-to-image-translation/\n",
        "#https://stackoverflow.com/questions/69085333/input-has-undefined-rank-tensorshapenone-error-in-building-resnet\n",
        "# defining generator\n",
        "def encoder_block(layer_in, filters, is_batch_norm = True, name = 'encoder_block'):\n",
        "    X = Conv2D(filters, kernel_size= (4,4), strides= (2,2), padding= 'same', kernel_initializer= RandomNormal(stddev= 0.02), name = name+'_conv')(layer_in)\n",
        "    if is_batch_norm:\n",
        "        X = BatchNormalization(name = name+'_bn')(X, training = True)\n",
        "    X = LeakyReLU(alpha = 0.2, name = name +'_activation')(X)\n",
        "    return X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Vu1VwG8Hy9q"
      },
      "source": [
        "def decoder_block(layer_in, skip_conn_layer, filters, is_dropout = True, name = 'decoder_block'):\n",
        "    X = Conv2DTranspose(filters, kernel_size= (4,4), strides= (2,2), padding= 'same', kernel_initializer= RandomNormal(stddev= 0.02), name = name+'_convT')(layer_in)\n",
        "    X = BatchNormalization(name = name+'_bn')(X, training = True)\n",
        "    if is_dropout:\n",
        "        X = Dropout(0.5, name = name+'_dropout')(X, training = True)\n",
        "    X = Concatenate(name = name +'_concat')([X, skip_conn_layer])\n",
        "    X = Activation('relu', name = name+'_activation')(X)\n",
        "    return X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhrwkuPY1uBw"
      },
      "source": [
        "def define_generator(input_shape):\n",
        "    input = Input(shape = input_shape, name = 'generator_input')\n",
        "\n",
        "    e1 = encoder_block(input, filters = 64, is_batch_norm= False, name= 'encoder_block_1')\n",
        "    e2 = encoder_block(e1, filters = 128, name = 'encoder_block_2')\n",
        "    e3 = encoder_block(e2, filters = 256, name = 'encoder_block_3')\n",
        "    e4 = encoder_block(e3, filters = 512, name = 'encoder_block_4')\n",
        "    e5 = encoder_block(e4, filters = 512, name = 'encoder_block_5')\n",
        "    e6 = encoder_block(e5, filters = 512, name = 'encoder_block_6')\n",
        "    e7 = encoder_block(e6, filters = 512, name = 'encoder_block_7')\n",
        "\n",
        "    # bottleneck \n",
        "    b = Conv2D(512, (4,4), strides=(2,2), padding='same', kernel_initializer= RandomNormal(stddev=0.02), name = 'bottleneck_conv')(e7)\n",
        "    b = Activation('relu', name= 'bottleneck_activation')(b)\n",
        "\n",
        "\t# decoder model\n",
        "    d1 = decoder_block(b, skip_conn_layer= e7, filters= 512, name = 'decoder_block_1')\n",
        "    d2 = decoder_block(d1, skip_conn_layer= e6, filters= 512, name = 'decoder_block_2')\n",
        "    d3 = decoder_block(d2, skip_conn_layer= e5, filters= 512, name = 'decoder_block_3')\n",
        "    d4 = decoder_block(d3, skip_conn_layer= e4, filters= 512, is_dropout=False, name = 'decoder_block_4')\n",
        "    d5 = decoder_block(d4, skip_conn_layer= e3, filters= 256, is_dropout=False, name = 'decoder_block_5')\n",
        "    d6 = decoder_block(d5, skip_conn_layer= e2, filters= 128, is_dropout= False, name = 'decoder_block_6')\n",
        "    d7 = decoder_block(d6, skip_conn_layer = e1, filters=64, is_dropout= False, name = 'decoder_block_7')\n",
        "\t# output\n",
        "    g = Conv2DTranspose(3, (4,4), strides=(2,2), padding='same', kernel_initializer=RandomNormal(stddev=0.02), name = 'output_conv')(d7)\n",
        "    out_image = Activation('tanh', name= 'output_activation')(g)\n",
        "    # define model\n",
        "    model = Model(input, out_image, name ='Generator')\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wWTIqP0jS99K"
      },
      "source": [
        "#### Defining Discriminator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJdWCkU7bRYD"
      },
      "source": [
        "def discriminator_block(layer_in, filters,stride =2, padding='same', is_batch_norm = True, name = 'discriminator_block'):\n",
        "    X = Conv2D(filters, kernel_size= (4,4), strides= stride, padding= padding, kernel_initializer= RandomNormal(stddev= 0.02), name = name+'_conv' )(layer_in)\n",
        "    if is_batch_norm:\n",
        "        X = BatchNormalization(name = name+'_bn')(X)\n",
        "    X = LeakyReLU(alpha = 0.2, name = name+'_leakyrelu')(X)\n",
        "    return X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1mqbCWudDrY"
      },
      "source": [
        "#https://www.tensorflow.org/tutorials/generative/pix2pix#build_the_discriminator\n",
        "def define_discriminator(input_shape):\n",
        "    '''This function takes in shape of image as input and return discriminator model '''\n",
        "    in_source_image = Input(shape= input_shape, name = 'discriminator_source_image_input')\n",
        "    in_target_image = Input(shape= input_shape, name = 'discriminator_target_image_input')\n",
        "    discriminator_input = Concatenate()([in_source_image, in_target_image])\n",
        "\n",
        "    d1 = discriminator_block(discriminator_input, filters= 64, is_batch_norm= False, name = 'discriminator_block_1')\n",
        "    d2 = discriminator_block(d1, filters= 128, name = 'discriminator_block_2')\n",
        "    d3 = discriminator_block(d2, filters = 256, name = 'discriminator_block_3')\n",
        "\n",
        "    pad1 = ZeroPadding2D(name = 'padding_1')(d3)\n",
        "    \n",
        "    d4 = discriminator_block(pad1, filters= 512,stride =1,padding ='valid', name = 'discriminator_block_4')\n",
        "\n",
        "    pad2 = ZeroPadding2D(name = 'padding_2')(d4)\n",
        "    \n",
        "    output_conv = Conv2D(filters= 1, kernel_size= (4,4), kernel_initializer= RandomNormal(stddev= 0.02), name='output_conv')(pad2)\n",
        "    output = Activation('sigmoid')(output_conv)\n",
        "    model = Model([in_source_image, in_target_image], output, name ='Discriminator')\n",
        "\n",
        "    model.compile(loss ='binary_crossentropy', optimizer= Adam(learning_rate= 0.0002, beta_1= 0.5), loss_weights= [0.5])\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EgeQY4wcTSQy"
      },
      "source": [
        "#### Defining CGAN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMa0r0PElRgq"
      },
      "source": [
        "def define_cgan(generator, discriminator, input_shape):\n",
        "    for layer in discriminator.layers:\n",
        "        layer.trainable = False\n",
        "    \n",
        "    input_source = Input(shape=input_shape, name = 'cgan_input')\n",
        "\n",
        "    gen_out = generator(input_source)\n",
        "\n",
        "    dis_out = discriminator([input_source, gen_out])\n",
        "\n",
        "    model = Model(input_source, [dis_out, gen_out], name ='CGAN')\n",
        "\n",
        "    model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.0002, beta_1=0.5))\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oCUcggoCTaKf"
      },
      "source": [
        "#### Generating samples for training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xlm42a9oMjif"
      },
      "source": [
        "#https://machinelearningmastery.com/how-to-develop-a-pix2pix-gan-for-image-to-image-translation/\n",
        "def generate_real_samples(sat_images, map_images, batch_size, patch_size):\n",
        "    sample = np.random.randint(0,sat_images.shape[0],batch_size)\n",
        "    sample_sat_image = sat_images[sample]\n",
        "    sample_map_image = map_images[sample]\n",
        "\n",
        "    y = np.ones((batch_size, patch_size, patch_size, 1))\n",
        "    y = np.where(y == 1, 0.9, 1)\n",
        "    return [sample_sat_image, sample_map_image] , y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UP503eY7Z_pW"
      },
      "source": [
        "def generate_fake_samples(sample, generator, patch_size):\n",
        "    X = generator.predict(sample)\n",
        "    y = np.zeros((len(X), patch_size, patch_size, 1))\n",
        "    return X, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36-TKRbXfyNr"
      },
      "source": [
        "#### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJiFZKPSU9ck"
      },
      "source": [
        "#https://machinelearningmastery.com/how-to-develop-a-pix2pix-gan-for-image-to-image-translation/\n",
        "# generate samples and save as a plot and save the model\n",
        "def summarize_performance(epoch, generator, sat_images, map_images, n_samples=3):\n",
        "\t# select a sample of input images\n",
        "\t[X_sat_image_real, X_map_image_real], _ = generate_real_samples(sat_images, map_images, n_samples, 1)\n",
        "\t\n",
        "    # generate a batch of fake samples\n",
        "\tmap_image_generated, _ = generate_fake_samples(X_sat_image_real, generator, 1)\n",
        "\n",
        "    # scale all pixels from [-1,1] to [0,1]\n",
        "\tX_sat_image_real = (X_sat_image_real + 1) / 2.0\n",
        "\tX_map_image_real = (X_map_image_real + 1) / 2.0\n",
        "\tmap_image_generated = (map_image_generated + 1) / 2.0\n",
        "\n",
        "\t# plot real source images\n",
        "\tfor i in range(n_samples):\n",
        "\t\tplt.subplot(3, n_samples, 1 + i)\n",
        "\t\tplt.axis('off')\n",
        "\t\tplt.imshow(X_sat_image_real[i])\n",
        "\t\n",
        "    # plot generated target image\n",
        "\tfor i in range(n_samples):\n",
        "\t\tplt.subplot(3, n_samples, 1 + n_samples + i)\n",
        "\t\tplt.axis('off')\n",
        "\t\tplt.imshow(map_image_generated[i])\n",
        "\t\n",
        "    # plot real target image\n",
        "\tfor i in range(n_samples):\n",
        "\t\tplt.subplot(3, n_samples, 1 + n_samples*2 + i)\n",
        "\t\tplt.axis('off')\n",
        "\t\tplt.imshow(X_map_image_real[i])\n",
        "\t\n",
        "    # save plot to file\n",
        "\tfilename1 = 'plot_{}.png'.format(epoch)\n",
        "\tplt.savefig(filename1)\n",
        "\tplt.close()\n",
        "\t\n",
        "    # save the generator model\n",
        "\tfilename2 = 'model_{}.h5'.format(epoch)\n",
        "\tgenerator.save(filename2)\n",
        "\tprint('>Saved: %s and %s' % (filename1, filename2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWd-f0WXbOEq"
      },
      "source": [
        "def train(discriminator, generator, cgan_model, sat_images, map_images, epochs = 100, batch_size = 1):\n",
        "    patch_size = discriminator.output_shape[1]\n",
        "    batch_per_epoch = int(len(sat_images)/ batch_size)\n",
        "    steps = batch_per_epoch*epochs\n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "        print('Epoch: {}/{}'.format(epoch+1, epochs))\n",
        "        for step in range(batch_per_epoch):\n",
        "            [X_sat_real, X_map_real],  y_real = generate_real_samples(sat_images, map_images, batch_size, patch_size)\n",
        "            X_map_fake, y_fake = generate_fake_samples(X_sat_real, generator, patch_size)\n",
        "\n",
        "            d_loss1 = discriminator.train_on_batch([X_sat_real, X_map_real], y_real)\n",
        "            d_loss2 = discriminator.train_on_batch([X_sat_real, X_map_fake], y_fake)\n",
        "            \n",
        "            g_loss, _, _ = cgan_model.train_on_batch(X_sat_real, [y_real, X_map_real])\n",
        "            if((step+1) % 10 == 0):\n",
        "                print('.',end = '')\n",
        "            if((step+1)%100 == 0):\n",
        "                print(' Batch {}/{} d_loss1:{} d_loss2 :{} g_loss :{}'.format(step+1,batch_per_epoch, d_loss1, d_loss2, g_loss))\n",
        "\t\t\n",
        "        # summarize model performance every 10 epochs\n",
        "        if ((epoch + 1) % 10 == 0):\n",
        "            summarize_performance(epoch+1, generator, sat_images, map_images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4MUPkQgOnU_g"
      },
      "source": [
        "image_shape = train_sat_images.shape[1:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yWjEwtG6qQqb",
        "outputId": "b3ad1c9b-95f6-45c4-a79b-0fe5ca8616b0"
      },
      "source": [
        "discriminator = define_discriminator(image_shape)\n",
        "generator = define_generator(image_shape)\n",
        "cgan = define_cgan(generator, discriminator, image_shape)\n",
        "\n",
        "train(discriminator, generator, cgan, train_sat_images, train_map_images)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1/100\n",
            ".......... Batch 100/1096 d_loss1:0.16825978457927704 d_loss2 :0.002018260071054101 g_loss :1.2972137928009033\n",
            ".......... Batch 200/1096 d_loss1:0.1668430119752884 d_loss2 :0.001436593709513545 g_loss :1.2635650634765625\n",
            ".......... Batch 300/1096 d_loss1:0.16948825120925903 d_loss2 :0.000943795486818999 g_loss :0.983384370803833\n",
            ".......... Batch 400/1096 d_loss1:0.16429613530635834 d_loss2 :0.00059362972388044 g_loss :1.0271698236465454\n",
            ".......... Batch 500/1096 d_loss1:0.16391333937644958 d_loss2 :0.0004522883100435138 g_loss :0.9404311776161194\n",
            ".......... Batch 600/1096 d_loss1:0.1682325303554535 d_loss2 :0.006424477323889732 g_loss :1.2276116609573364\n",
            ".......... Batch 700/1096 d_loss1:0.16430625319480896 d_loss2 :0.0029567331075668335 g_loss :1.0965291261672974\n",
            ".......... Batch 800/1096 d_loss1:0.16466404497623444 d_loss2 :0.0014442948158830404 g_loss :0.9964359998703003\n",
            ".......... Batch 900/1096 d_loss1:0.1642521321773529 d_loss2 :0.0007079546921886504 g_loss :0.954795777797699\n",
            ".......... Batch 1000/1096 d_loss1:0.16381265223026276 d_loss2 :0.0006049250951036811 g_loss :0.9334124326705933\n",
            ".........Epoch: 2/100\n",
            ".......... Batch 100/1096 d_loss1:0.16361497342586517 d_loss2 :0.0002669907407835126 g_loss :1.0927938222885132\n",
            ".......... Batch 200/1096 d_loss1:0.16332344710826874 d_loss2 :0.0001673850347287953 g_loss :1.0591661930084229\n",
            ".......... Batch 300/1096 d_loss1:0.1629233956336975 d_loss2 :0.00017757379100658 g_loss :0.9616776704788208\n",
            ".......... Batch 400/1096 d_loss1:0.16285917162895203 d_loss2 :8.68141432874836e-05 g_loss :0.9058336019515991\n",
            ".......... Batch 500/1096 d_loss1:0.16286173462867737 d_loss2 :0.00010322916932636872 g_loss :0.9428449869155884\n",
            ".......... Batch 600/1096 d_loss1:0.16288787126541138 d_loss2 :0.00010570245649432763 g_loss :0.993323564529419\n",
            ".......... Batch 700/1096 d_loss1:0.16276510059833527 d_loss2 :0.00018249342974741012 g_loss :1.0409154891967773\n",
            ".......... Batch 800/1096 d_loss1:0.1641997992992401 d_loss2 :0.00017609189671929926 g_loss :1.0075862407684326\n",
            ".......... Batch 900/1096 d_loss1:0.16280966997146606 d_loss2 :0.00016166517161764205 g_loss :1.0874323844909668\n",
            ".......... Batch 1000/1096 d_loss1:0.16283440589904785 d_loss2 :5.534204683499411e-05 g_loss :1.1113781929016113\n",
            ".........Epoch: 3/100\n",
            ".......... Batch 100/1096 d_loss1:0.16326063871383667 d_loss2 :5.001198223908432e-05 g_loss :1.1978873014450073\n",
            ".......... Batch 200/1096 d_loss1:0.16384895145893097 d_loss2 :4.061801519128494e-05 g_loss :0.9748783111572266\n",
            ".......... Batch 300/1096 d_loss1:0.16284584999084473 d_loss2 :4.5952114305691794e-05 g_loss :0.9227522611618042\n",
            ".......... Batch 400/1096 d_loss1:0.1639813780784607 d_loss2 :3.903539982275106e-05 g_loss :1.1846206188201904\n",
            ".......... Batch 500/1096 d_loss1:0.163345605134964 d_loss2 :4.695534153142944e-05 g_loss :1.0922297239303589\n",
            ".......... Batch 600/1096 d_loss1:0.16363385319709778 d_loss2 :4.063609230797738e-05 g_loss :1.0613363981246948\n",
            ".......... Batch 700/1096 d_loss1:0.16362543404102325 d_loss2 :3.347473466419615e-05 g_loss :1.1440407037734985\n",
            ".......... Batch 800/1096 d_loss1:0.16281944513320923 d_loss2 :4.0046721551334485e-05 g_loss :0.9676960706710815\n",
            ".......... Batch 900/1096 d_loss1:0.1633785367012024 d_loss2 :4.1828316170722246e-05 g_loss :1.090259075164795\n",
            ".......... Batch 1000/1096 d_loss1:0.16316160559654236 d_loss2 :3.3438376703998074e-05 g_loss :1.0531781911849976\n",
            ".........Epoch: 4/100\n",
            ".......... Batch 100/1096 d_loss1:0.1629153937101364 d_loss2 :3.3606309443712234e-05 g_loss :1.1514647006988525\n",
            ".......... Batch 200/1096 d_loss1:0.16398942470550537 d_loss2 :3.08800044876989e-05 g_loss :1.0368870496749878\n",
            ".......... Batch 300/1096 d_loss1:0.16325747966766357 d_loss2 :3.410247154533863e-05 g_loss :1.0290554761886597\n",
            ".......... Batch 400/1096 d_loss1:0.16280414164066315 d_loss2 :2.6054611225845292e-05 g_loss :1.0290216207504272\n",
            ".......... Batch 500/1096 d_loss1:0.16399937868118286 d_loss2 :2.7030420824303292e-05 g_loss :1.1480002403259277\n",
            ".......... Batch 600/1096 d_loss1:0.1679316610097885 d_loss2 :0.0046692234463989735 g_loss :5.177460670471191\n",
            ".......... Batch 700/1096 d_loss1:0.16329319775104523 d_loss2 :0.001349227037280798 g_loss :4.377362251281738\n",
            ".......... Batch 800/1096 d_loss1:0.16521747410297394 d_loss2 :0.003856063587591052 g_loss :2.2297308444976807\n",
            ".......... Batch 900/1096 d_loss1:0.16448403894901276 d_loss2 :0.0010639437241479754 g_loss :1.5036447048187256\n",
            ".......... Batch 1000/1096 d_loss1:0.16452628374099731 d_loss2 :0.0015399305848404765 g_loss :1.2748090028762817\n",
            ".........Epoch: 5/100\n",
            ".......... Batch 100/1096 d_loss1:0.1632762998342514 d_loss2 :0.0002073072682833299 g_loss :1.0419886112213135\n",
            ".......... Batch 200/1096 d_loss1:0.16306941211223602 d_loss2 :0.00018874167290050536 g_loss :1.0164084434509277\n",
            ".......... Batch 300/1096 d_loss1:0.16312101483345032 d_loss2 :0.00027062464505434036 g_loss :0.9789285659790039\n",
            ".......... Batch 400/1096 d_loss1:0.16623346507549286 d_loss2 :0.00031699222745373845 g_loss :0.9949818849563599\n",
            ".......... Batch 500/1096 d_loss1:0.1626949906349182 d_loss2 :0.0003591688582673669 g_loss :1.1077935695648193\n",
            ".......... Batch 600/1096 d_loss1:0.16263075172901154 d_loss2 :0.00013876806769985706 g_loss :0.987463116645813\n",
            ".......... Batch 700/1096 d_loss1:0.16268101334571838 d_loss2 :8.971452916739509e-05 g_loss :1.0775552988052368\n",
            ".......... Batch 800/1096 d_loss1:0.1629355400800705 d_loss2 :7.829647802282125e-05 g_loss :1.0536316633224487\n",
            ".......... Batch 900/1096 d_loss1:0.16347911953926086 d_loss2 :7.358056609518826e-05 g_loss :1.123953104019165\n",
            ".......... Batch 1000/1096 d_loss1:0.16266843676567078 d_loss2 :6.931493408046663e-05 g_loss :1.076890230178833\n",
            ".........Epoch: 6/100\n",
            ".......... Batch 100/1096 d_loss1:0.1631447821855545 d_loss2 :0.00019415337010286748 g_loss :1.1540392637252808\n",
            ".......... Batch 200/1096 d_loss1:0.1631844937801361 d_loss2 :0.0001165527937700972 g_loss :1.1010143756866455\n",
            ".......... Batch 300/1096 d_loss1:0.1635715812444687 d_loss2 :0.011537238024175167 g_loss :1.5957376956939697\n",
            ".......... Batch 400/1096 d_loss1:0.16593553125858307 d_loss2 :0.0007547481800429523 g_loss :1.2315573692321777\n",
            ".......... Batch 500/1096 d_loss1:0.22807075083255768 d_loss2 :0.13100001215934753 g_loss :10.193883895874023\n",
            ".......... Batch 600/1096 d_loss1:0.16398929059505463 d_loss2 :0.0004780837334692478 g_loss :1.2174458503723145\n",
            ".......... Batch 700/1096 d_loss1:0.16680727899074554 d_loss2 :0.0007458555628545582 g_loss :0.9536246061325073\n",
            ".......... Batch 800/1096 d_loss1:0.16425393521785736 d_loss2 :0.0005440934910438955 g_loss :1.2728544473648071\n",
            ".......... Batch 900/1096 d_loss1:0.16377562284469604 d_loss2 :0.00038471969310194254 g_loss :1.0807828903198242\n",
            ".......... Batch 1000/1096 d_loss1:0.1633874475955963 d_loss2 :0.0009081208845600486 g_loss :0.9880028963088989\n",
            ".........Epoch: 7/100\n",
            ".......... Batch 100/1096 d_loss1:0.16384752094745636 d_loss2 :0.0002587050257716328 g_loss :1.2875508069992065\n",
            ".......... Batch 200/1096 d_loss1:0.16326647996902466 d_loss2 :0.00018503588216844946 g_loss :1.159303903579712\n",
            ".......... Batch 300/1096 d_loss1:0.1628897488117218 d_loss2 :0.00036773525062017143 g_loss :1.1490994691848755\n",
            ".......... Batch 400/1096 d_loss1:0.16279025375843048 d_loss2 :0.0005075524095445871 g_loss :1.0969723463058472\n",
            ".......... Batch 500/1096 d_loss1:0.16282440721988678 d_loss2 :0.00026588133187033236 g_loss :1.179553747177124\n",
            ".......... Batch 600/1096 d_loss1:0.16399730741977692 d_loss2 :0.0001526575506431982 g_loss :1.0994739532470703\n",
            ".......... Batch 700/1096 d_loss1:0.16296301782131195 d_loss2 :0.00017795288295019418 g_loss :1.0383949279785156\n",
            ".......... Batch 800/1096 d_loss1:0.1628374457359314 d_loss2 :0.00012965219502802938 g_loss :1.136131763458252\n",
            ".......... Batch 900/1096 d_loss1:0.1639399528503418 d_loss2 :6.704895349685103e-05 g_loss :1.2852109670639038\n",
            ".......... Batch 1000/1096 d_loss1:0.1627718061208725 d_loss2 :6.038869469193742e-05 g_loss :1.0662922859191895\n",
            ".........Epoch: 8/100\n",
            ".......... Batch 100/1096 d_loss1:0.1641448438167572 d_loss2 :6.331557960947976e-05 g_loss :1.0618228912353516\n",
            ".......... Batch 200/1096 d_loss1:0.16271749138832092 d_loss2 :4.7966514102881774e-05 g_loss :0.9472811222076416\n",
            ".......... Batch 300/1096 d_loss1:0.1639341413974762 d_loss2 :6.99504598742351e-05 g_loss :1.080561876296997\n",
            ".......... Batch 400/1096 d_loss1:0.16335511207580566 d_loss2 :6.189590931171551e-05 g_loss :0.990357518196106\n",
            ".......... Batch 500/1096 d_loss1:0.16287140548229218 d_loss2 :2.7761365345213562e-05 g_loss :0.9308303594589233\n",
            ".......... Batch 600/1096 d_loss1:0.16330046951770782 d_loss2 :1.8230948626296595e-05 g_loss :1.0618085861206055\n",
            ".......... Batch 700/1096 d_loss1:0.1630004197359085 d_loss2 :3.853482485283166e-05 g_loss :1.060042142868042\n",
            ".......... Batch 800/1096 d_loss1:0.16302822530269623 d_loss2 :1.595542016730178e-05 g_loss :1.0232692956924438\n",
            ".......... Batch 900/1096 d_loss1:0.16308367252349854 d_loss2 :2.2980177163844928e-05 g_loss :1.0496416091918945\n",
            ".......... Batch 1000/1096 d_loss1:0.16481657326221466 d_loss2 :2.0154106096015312e-05 g_loss :0.9336860775947571\n",
            ".........Epoch: 9/100\n",
            ".......... Batch 100/1096 d_loss1:0.16261553764343262 d_loss2 :8.654352131998166e-05 g_loss :0.9551196098327637\n",
            ".......... Batch 200/1096 d_loss1:0.16291721165180206 d_loss2 :2.6671617888496257e-05 g_loss :0.9699732661247253\n",
            ".......... Batch 300/1096 d_loss1:0.1627912074327469 d_loss2 :2.583877540018875e-05 g_loss :0.9423421621322632\n",
            ".......... Batch 400/1096 d_loss1:0.16344133019447327 d_loss2 :1.5713922039140016e-05 g_loss :1.005062460899353\n",
            ".......... Batch 500/1096 d_loss1:0.1627289056777954 d_loss2 :4.095957046956755e-05 g_loss :0.9328325986862183\n",
            ".......... Batch 600/1096 d_loss1:0.16324149072170258 d_loss2 :2.355149990762584e-05 g_loss :0.9410197734832764\n",
            ".......... Batch 700/1096 d_loss1:0.16311781108379364 d_loss2 :1.1146279575768858e-05 g_loss :1.1739226579666138\n",
            ".......... Batch 800/1096 d_loss1:0.1634569764137268 d_loss2 :1.1463614100648556e-05 g_loss :0.953758716583252\n",
            ".......... Batch 900/1096 d_loss1:0.1626720130443573 d_loss2 :3.293465852038935e-05 g_loss :0.8642321825027466\n",
            ".......... Batch 1000/1096 d_loss1:0.16416016221046448 d_loss2 :1.2837682334065903e-05 g_loss :0.9743897914886475\n",
            ".........Epoch: 10/100\n",
            ".......... Batch 100/1096 d_loss1:0.16324837505817413 d_loss2 :6.525755452457815e-06 g_loss :1.0251812934875488\n",
            ".......... Batch 200/1096 d_loss1:0.1633613556623459 d_loss2 :3.0088618586887605e-05 g_loss :0.91191565990448\n",
            ".......... Batch 300/1096 d_loss1:0.16372260451316833 d_loss2 :2.1928764908807352e-05 g_loss :1.0460034608840942\n",
            ".......... Batch 400/1096 d_loss1:0.16453689336776733 d_loss2 :6.01118745180429e-06 g_loss :1.0329298973083496\n",
            ".......... Batch 500/1096 d_loss1:0.16930101811885834 d_loss2 :2.357155790377874e-05 g_loss :1.0227088928222656\n",
            ".......... Batch 600/1096 d_loss1:0.1628846675157547 d_loss2 :7.016836661932757e-06 g_loss :0.9476683139801025\n",
            ".......... Batch 700/1096 d_loss1:0.16319766640663147 d_loss2 :6.0993370425421745e-06 g_loss :0.9462713003158569\n",
            ".......... Batch 800/1096 d_loss1:0.16278672218322754 d_loss2 :6.739360742358258e-06 g_loss :1.1605619192123413\n",
            ".......... Batch 900/1096 d_loss1:0.1630406677722931 d_loss2 :7.323404133785516e-06 g_loss :0.9993622899055481\n",
            ".......... Batch 1000/1096 d_loss1:0.163101464509964 d_loss2 :4.981952770322096e-06 g_loss :1.1880085468292236\n",
            ".........WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            ">Saved: plot_10.png and model_10.h5\n",
            "Epoch: 11/100\n",
            ".......... Batch 100/1096 d_loss1:0.16323697566986084 d_loss2 :3.032316499229637e-06 g_loss :1.0135498046875\n",
            ".......... Batch 200/1096 d_loss1:0.1634037345647812 d_loss2 :6.0003776525263675e-06 g_loss :1.0261008739471436\n",
            ".......... Batch 300/1096 d_loss1:0.16298747062683105 d_loss2 :3.612286718635005e-06 g_loss :0.9234743118286133\n",
            ".......... Batch 400/1096 d_loss1:0.16350765526294708 d_loss2 :4.361020273790928e-06 g_loss :0.9075007438659668\n",
            ".......... Batch 500/1096 d_loss1:0.16294428706169128 d_loss2 :2.931314838860999e-06 g_loss :0.9776424765586853\n",
            ".......... Batch 600/1096 d_loss1:0.16311770677566528 d_loss2 :4.754861492983764e-06 g_loss :0.9187038540840149\n",
            ".......... Batch 700/1096 d_loss1:0.16301845014095306 d_loss2 :3.824297436949564e-06 g_loss :0.9148541688919067\n",
            ".......... Batch 800/1096 d_loss1:0.1629171073436737 d_loss2 :6.386786026268965e-06 g_loss :0.8966177701950073\n",
            ".......... Batch 900/1096 d_loss1:0.16420552134513855 d_loss2 :0.002239635679870844 g_loss :1.0392026901245117\n",
            ".......... Batch 1000/1096 d_loss1:0.17594467103481293 d_loss2 :0.0002912136842496693 g_loss :0.8963711261749268\n",
            ".........Epoch: 12/100\n",
            ".......... Batch 100/1096 d_loss1:0.1627475470304489 d_loss2 :0.00029383908258751035 g_loss :0.9057043790817261\n",
            ".......... Batch 200/1096 d_loss1:0.16273218393325806 d_loss2 :0.0002113820519298315 g_loss :0.991999089717865\n",
            ".......... Batch 300/1096 d_loss1:0.16305741667747498 d_loss2 :0.0001400533801643178 g_loss :1.112059473991394\n",
            ".......... Batch 400/1096 d_loss1:0.16273199021816254 d_loss2 :0.0001167563023045659 g_loss :0.988800048828125\n",
            ".......... Batch 500/1096 d_loss1:0.16260772943496704 d_loss2 :9.009524364955723e-05 g_loss :0.9059984683990479\n",
            ".......... Batch 600/1096 d_loss1:0.16261139512062073 d_loss2 :9.52230257098563e-05 g_loss :0.9489713907241821\n",
            ".......... Batch 700/1096 d_loss1:0.16263851523399353 d_loss2 :0.00016778986901044846 g_loss :0.9252358675003052\n",
            ".......... Batch 800/1096 d_loss1:0.16295090317726135 d_loss2 :4.480196366785094e-05 g_loss :0.8687028884887695\n",
            ".......... Batch 900/1096 d_loss1:0.1627984642982483 d_loss2 :2.9051341698504984e-05 g_loss :0.9735917448997498\n",
            ".......... Batch 1000/1096 d_loss1:0.16277898848056793 d_loss2 :4.6292745537357405e-05 g_loss :0.9291325807571411\n",
            ".........Epoch: 13/100\n",
            ".......... Batch 100/1096 d_loss1:0.16294366121292114 d_loss2 :1.737968523229938e-05 g_loss :0.8944965600967407\n",
            ".......... Batch 200/1096 d_loss1:0.16277167201042175 d_loss2 :1.5342304322985e-05 g_loss :0.8736586570739746\n",
            ".......... Batch 300/1096 d_loss1:0.16303597390651703 d_loss2 :1.2202464859001338e-05 g_loss :0.9719352722167969\n",
            ".......... Batch 400/1096 d_loss1:0.1630525439977646 d_loss2 :1.693491685728077e-05 g_loss :0.9279842376708984\n",
            ".......... Batch 500/1096 d_loss1:0.1636725515127182 d_loss2 :1.170249015558511e-05 g_loss :0.869659423828125\n",
            ".......... Batch 600/1096 d_loss1:0.16516950726509094 d_loss2 :1.131003227783367e-05 g_loss :0.8888067007064819\n",
            ".......... Batch 700/1096 d_loss1:0.1628332883119583 d_loss2 :1.3394340385275427e-05 g_loss :0.880629301071167\n",
            ".......... Batch 800/1096 d_loss1:0.16293159127235413 d_loss2 :1.0282972652930766e-05 g_loss :0.8862054944038391\n",
            ".......... Batch 900/1096 d_loss1:0.16284054517745972 d_loss2 :1.1822416126960889e-05 g_loss :1.121373176574707\n",
            ".......... Batch 1000/1096 d_loss1:0.162824809551239 d_loss2 :1.0456504242029041e-05 g_loss :0.9500200748443604\n",
            ".........Epoch: 14/100\n",
            ".......... Batch 100/1096 d_loss1:0.16296887397766113 d_loss2 :6.693680916214362e-06 g_loss :0.891697883605957\n",
            ".......... Batch 200/1096 d_loss1:0.1631343513727188 d_loss2 :7.901052413217258e-06 g_loss :0.980392336845398\n",
            ".......... Batch 300/1096 d_loss1:0.16279906034469604 d_loss2 :7.479371561203152e-06 g_loss :0.8886525630950928\n",
            ".......... Batch 400/1096 d_loss1:0.16287238895893097 d_loss2 :1.1536069905559998e-05 g_loss :0.8534533381462097\n",
            ".......... Batch 500/1096 d_loss1:0.16302455961704254 d_loss2 :0.00032596016535535455 g_loss :1.0742202997207642\n",
            ".......... Batch 600/1096 d_loss1:0.1632314920425415 d_loss2 :1.0613705853756983e-05 g_loss :0.9316447377204895\n",
            ".......... Batch 700/1096 d_loss1:0.1632973551750183 d_loss2 :1.4625281437474769e-05 g_loss :0.8814952373504639\n",
            ".......... Batch 800/1096 d_loss1:0.16349457204341888 d_loss2 :5.3925423344480805e-06 g_loss :0.885201096534729\n",
            ".......... Batch 900/1096 d_loss1:0.16289900243282318 d_loss2 :1.3509235031960998e-05 g_loss :0.8833860754966736\n",
            ".......... Batch 1000/1096 d_loss1:0.1631058007478714 d_loss2 :5.006507763027912e-06 g_loss :0.8809812068939209\n",
            ".........Epoch: 15/100\n",
            ".......... Batch 100/1096 d_loss1:0.163188174366951 d_loss2 :9.482860150455963e-06 g_loss :0.9233216047286987\n",
            ".......... Batch 200/1096 d_loss1:0.16261498630046844 d_loss2 :1.8758066289592534e-05 g_loss :1.0074211359024048\n",
            ".......... Batch 300/1096 d_loss1:0.16266997158527374 d_loss2 :5.717125986848259e-06 g_loss :0.9509189128875732\n",
            ".......... Batch 400/1096 d_loss1:0.1628987193107605 d_loss2 :5.336224603524897e-06 g_loss :0.8996329307556152\n",
            ".......... Batch 500/1096 d_loss1:0.1628900021314621 d_loss2 :6.254181244003121e-06 g_loss :0.8978772163391113\n",
            ".......... Batch 600/1096 d_loss1:0.16390274465084076 d_loss2 :7.264801752171479e-06 g_loss :0.9194434881210327\n",
            ".......... Batch 700/1096 d_loss1:0.16283674538135529 d_loss2 :6.647266218351433e-06 g_loss :0.9140833616256714\n",
            ".......... Batch 800/1096 d_loss1:0.16323381662368774 d_loss2 :0.000427994760684669 g_loss :0.8248772621154785\n",
            ".......... Batch 900/1096 d_loss1:0.16273070871829987 d_loss2 :0.00025409337831661105 g_loss :0.9056442975997925\n",
            ".......... Batch 1000/1096 d_loss1:0.1632355898618698 d_loss2 :0.0001661207206780091 g_loss :0.9464999437332153\n",
            ".........Epoch: 16/100\n",
            ".......... Batch 100/1096 d_loss1:0.16322872042655945 d_loss2 :0.0004370923270471394 g_loss :0.9158004522323608\n",
            ".......... Batch 200/1096 d_loss1:0.1625908464193344 d_loss2 :0.0001781949686119333 g_loss :0.8557491302490234\n",
            ".......... Batch 300/1096 d_loss1:0.16267867386341095 d_loss2 :6.75990668241866e-05 g_loss :0.9777197241783142\n",
            ".......... Batch 400/1096 d_loss1:0.16265086829662323 d_loss2 :2.4998556909849867e-05 g_loss :0.9910720586776733\n",
            ".......... Batch 500/1096 d_loss1:0.1626146286725998 d_loss2 :2.39790570049081e-05 g_loss :1.020874261856079\n",
            ".......... Batch 600/1096 d_loss1:0.16260294616222382 d_loss2 :1.785370295692701e-05 g_loss :0.9844401478767395\n",
            ".......... Batch 700/1096 d_loss1:0.16264019906520844 d_loss2 :3.002072662638966e-05 g_loss :1.0287305116653442\n",
            ".......... Batch 800/1096 d_loss1:0.16259174048900604 d_loss2 :5.587564010056667e-05 g_loss :1.0686781406402588\n",
            ".......... Batch 900/1096 d_loss1:0.16257207095623016 d_loss2 :2.8151196602266282e-05 g_loss :0.9653701186180115\n",
            ".......... Batch 1000/1096 d_loss1:0.1627253144979477 d_loss2 :5.879412856302224e-05 g_loss :0.8775097131729126\n",
            ".........Epoch: 17/100\n",
            ".......... Batch 100/1096 d_loss1:0.16320013999938965 d_loss2 :1.1046065083064605e-05 g_loss :0.8246870040893555\n",
            ".......... Batch 200/1096 d_loss1:0.16272985935211182 d_loss2 :2.933707946795039e-05 g_loss :0.9335833191871643\n",
            ".......... Batch 300/1096 d_loss1:0.1626971811056137 d_loss2 :2.1222978830337524e-05 g_loss :0.8397825956344604\n",
            ".......... Batch 400/1096 d_loss1:0.16292914748191833 d_loss2 :1.0733086128311697e-05 g_loss :0.8321245908737183\n",
            ".......... Batch 500/1096 d_loss1:0.1635567545890808 d_loss2 :6.034256330167409e-06 g_loss :0.871930718421936\n",
            ".......... Batch 600/1096 d_loss1:0.16285261511802673 d_loss2 :0.00011319229088257998 g_loss :0.8234167098999023\n",
            ".......... Batch 700/1096 d_loss1:0.16273143887519836 d_loss2 :0.00014944147551432252 g_loss :1.0733624696731567\n",
            ".......... Batch 800/1096 d_loss1:0.16275553405284882 d_loss2 :9.342000703327358e-05 g_loss :0.8940194249153137\n",
            ".......... Batch 900/1096 d_loss1:0.1626860797405243 d_loss2 :0.00010773263784358278 g_loss :0.8931034803390503\n",
            ".......... Batch 1000/1096 d_loss1:0.16260352730751038 d_loss2 :5.011527537135407e-05 g_loss :0.8430463075637817\n",
            ".........Epoch: 18/100\n",
            ".......... Batch 100/1096 d_loss1:0.16259799897670746 d_loss2 :1.6576590496697463e-05 g_loss :0.8285948038101196\n",
            ".......... Batch 200/1096 d_loss1:0.16260983049869537 d_loss2 :1.2966663234692533e-05 g_loss :0.8386999368667603\n",
            ".......... Batch 300/1096 d_loss1:0.1627950519323349 d_loss2 :2.0472018150030635e-05 g_loss :0.9341433048248291\n",
            ".......... Batch 400/1096 d_loss1:0.16264133155345917 d_loss2 :2.0509840396698564e-05 g_loss :0.8478540778160095\n",
            ".......... Batch 500/1096 d_loss1:0.1636534184217453 d_loss2 :1.6294970919261687e-05 g_loss :0.8748337030410767\n",
            ".......... Batch 600/1096 d_loss1:0.1627892106771469 d_loss2 :1.6693225916242227e-05 g_loss :1.0998969078063965\n",
            ".......... Batch 700/1096 d_loss1:0.16296644508838654 d_loss2 :1.870594860520214e-05 g_loss :0.9590582847595215\n",
            ".......... Batch 800/1096 d_loss1:0.1628831923007965 d_loss2 :2.439076706650667e-05 g_loss :0.9485369920730591\n",
            ".......... Batch 900/1096 d_loss1:0.16278012096881866 d_loss2 :2.1590220057987608e-05 g_loss :1.0750612020492554\n",
            ".......... Batch 1000/1096 d_loss1:0.162888303399086 d_loss2 :1.0193207344855182e-05 g_loss :0.9120427966117859\n",
            ".........Epoch: 19/100\n",
            ".......... Batch 100/1096 d_loss1:0.16268467903137207 d_loss2 :2.9570057449745946e-05 g_loss :0.899431586265564\n",
            ".......... Batch 200/1096 d_loss1:0.16276083886623383 d_loss2 :1.7470189050072804e-05 g_loss :1.002795696258545\n",
            ".......... Batch 300/1096 d_loss1:0.16268037259578705 d_loss2 :1.2024440366076306e-05 g_loss :0.8400367498397827\n",
            ".......... Batch 400/1096 d_loss1:0.16292335093021393 d_loss2 :7.692968210903928e-06 g_loss :0.8583033084869385\n",
            ".......... Batch 500/1096 d_loss1:0.16298294067382812 d_loss2 :6.999282959441189e-06 g_loss :1.1483230590820312\n",
            ".......... Batch 600/1096 d_loss1:0.1629648506641388 d_loss2 :2.2815849661128595e-05 g_loss :0.9753525257110596\n",
            ".......... Batch 700/1096 d_loss1:0.16295857727527618 d_loss2 :1.2539220733742695e-05 g_loss :0.882533073425293\n",
            ".......... Batch 800/1096 d_loss1:0.16280019283294678 d_loss2 :4.458721377886832e-06 g_loss :0.9285240173339844\n",
            ".......... Batch 900/1096 d_loss1:0.16271308064460754 d_loss2 :5.091797447676072e-06 g_loss :0.8795827627182007\n",
            ".......... Batch 1000/1096 d_loss1:0.16279280185699463 d_loss2 :3.304471647425089e-06 g_loss :0.9079047441482544\n",
            ".........Epoch: 20/100\n",
            ".......... Batch 100/1096 d_loss1:0.16277895867824554 d_loss2 :7.142496997403214e-06 g_loss :1.0413860082626343\n",
            ".......... Batch 200/1096 d_loss1:0.16291218996047974 d_loss2 :3.1664610560255824e-06 g_loss :1.006192684173584\n",
            ".......... Batch 300/1096 d_loss1:0.16297844052314758 d_loss2 :0.0006430273642763495 g_loss :0.8895367383956909\n",
            ".......... Batch 400/1096 d_loss1:0.162824347615242 d_loss2 :3.6067974633624544e-06 g_loss :0.9003803730010986\n",
            ".......... Batch 500/1096 d_loss1:0.16290324926376343 d_loss2 :3.3583185086172307e-06 g_loss :0.8465847969055176\n",
            ".......... Batch 600/1096 d_loss1:0.1628263294696808 d_loss2 :2.93878201773623e-06 g_loss :0.866096556186676\n",
            ".......... Batch 700/1096 d_loss1:0.16273564100265503 d_loss2 :4.519283265835838e-06 g_loss :0.93630450963974\n",
            ".......... Batch 800/1096 d_loss1:0.1626274734735489 d_loss2 :2.9649318094016053e-06 g_loss :0.9001109600067139\n",
            ".......... Batch 900/1096 d_loss1:0.16283831000328064 d_loss2 :2.101440486512729e-06 g_loss :0.8622660040855408\n",
            ".......... Batch 1000/1096 d_loss1:0.16303753852844238 d_loss2 :4.346412424638402e-06 g_loss :0.8875999450683594\n",
            ".........WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            ">Saved: plot_20.png and model_20.h5\n",
            "Epoch: 21/100\n",
            ".......... Batch 100/1096 d_loss1:0.16280433535575867 d_loss2 :2.788588290059124e-06 g_loss :1.044155478477478\n",
            ".......... Batch 200/1096 d_loss1:0.16290581226348877 d_loss2 :1.9653921299322974e-06 g_loss :0.83668053150177\n",
            ".......... Batch 300/1096 d_loss1:0.1628764122724533 d_loss2 :3.5107477742712945e-06 g_loss :0.9333289861679077\n",
            ".......... Batch 400/1096 d_loss1:0.17175047099590302 d_loss2 :0.0019307488109916449 g_loss :1.027329683303833\n",
            ".......... Batch 500/1096 d_loss1:0.17058958113193512 d_loss2 :0.00187730323523283 g_loss :0.9878256320953369\n",
            ".......... Batch 600/1096 d_loss1:0.16652964055538177 d_loss2 :0.00047633220674470067 g_loss :0.9349049925804138\n",
            ".......... Batch 700/1096 d_loss1:0.16300971806049347 d_loss2 :9.985147335100919e-05 g_loss :1.0240546464920044\n",
            ".......... Batch 800/1096 d_loss1:0.16294234991073608 d_loss2 :6.333840428851545e-05 g_loss :1.0196707248687744\n",
            ".......... Batch 900/1096 d_loss1:0.16277821362018585 d_loss2 :4.1649036575108767e-05 g_loss :0.9243711233139038\n",
            ".......... Batch 1000/1096 d_loss1:0.16260910034179688 d_loss2 :2.457242226228118e-05 g_loss :0.9330413341522217\n",
            ".........Epoch: 22/100\n",
            ".......... Batch 100/1096 d_loss1:0.16265305876731873 d_loss2 :3.981520058005117e-05 g_loss :0.914636492729187\n",
            ".......... Batch 200/1096 d_loss1:0.16273006796836853 d_loss2 :3.1569066777592525e-05 g_loss :0.8712209463119507\n",
            ".......... Batch 300/1096 d_loss1:0.1625734120607376 d_loss2 :3.1157684134086594e-05 g_loss :0.8735912442207336\n",
            ".......... Batch 400/1096 d_loss1:0.1625588834285736 d_loss2 :2.2985730538493954e-05 g_loss :0.9105478525161743\n",
            ".......... Batch 500/1096 d_loss1:0.16271443665027618 d_loss2 :2.78806037385948e-05 g_loss :0.926650881767273\n",
            ".......... Batch 600/1096 d_loss1:0.16268830001354218 d_loss2 :2.0224812033120543e-05 g_loss :0.919497549533844\n",
            ".......... Batch 700/1096 d_loss1:0.16263732314109802 d_loss2 :1.1162186638102867e-05 g_loss :0.9371909499168396\n",
            ".......... Batch 800/1096 d_loss1:0.16259697079658508 d_loss2 :1.584918391017709e-05 g_loss :1.028752088546753\n",
            ".......... Batch 900/1096 d_loss1:0.16264905035495758 d_loss2 :1.0563969226495828e-05 g_loss :0.8783485889434814\n",
            ".......... Batch 1000/1096 d_loss1:0.16290193796157837 d_loss2 :7.158959306252655e-06 g_loss :0.8548930287361145\n",
            ".........Epoch: 23/100\n",
            ".......... Batch 100/1096 d_loss1:0.1627875119447708 d_loss2 :5.702684120478807e-06 g_loss :0.8412647247314453\n",
            ".......... Batch 200/1096 d_loss1:0.16268014907836914 d_loss2 :6.905705959070474e-06 g_loss :0.9089553356170654\n",
            ".......... Batch 300/1096 d_loss1:0.16280557215213776 d_loss2 :5.538813184102764e-06 g_loss :0.9215011596679688\n",
            ".......... Batch 400/1096 d_loss1:0.1626933068037033 d_loss2 :7.562388418591581e-06 g_loss :0.8757926225662231\n",
            ".......... Batch 500/1096 d_loss1:0.16323615610599518 d_loss2 :4.642219664674485e-06 g_loss :0.8773936629295349\n",
            ".......... Batch 600/1096 d_loss1:0.16263341903686523 d_loss2 :3.7335855722631095e-06 g_loss :0.8570638298988342\n",
            ".......... Batch 700/1096 d_loss1:0.16269533336162567 d_loss2 :7.996856766112614e-06 g_loss :1.0122716426849365\n",
            ".......... Batch 800/1096 d_loss1:0.16280771791934967 d_loss2 :3.877622020809213e-06 g_loss :0.8803153038024902\n",
            ".......... Batch 900/1096 d_loss1:0.16272135078907013 d_loss2 :6.4035848481580615e-06 g_loss :0.8647357225418091\n",
            ".......... Batch 1000/1096 d_loss1:0.16291289031505585 d_loss2 :4.7290536713262554e-06 g_loss :0.8511184453964233\n",
            ".........Epoch: 24/100\n",
            ".......... Batch 100/1096 d_loss1:0.16323478519916534 d_loss2 :9.309398592449725e-06 g_loss :0.7826383113861084\n",
            ".......... Batch 200/1096 d_loss1:0.16297492384910583 d_loss2 :4.850894583796617e-06 g_loss :0.9427953958511353\n",
            ".......... Batch 300/1096 d_loss1:0.16282212734222412 d_loss2 :5.344697456166614e-06 g_loss :0.8500744104385376\n",
            ".......... Batch 400/1096 d_loss1:0.16288471221923828 d_loss2 :5.168604275240796e-06 g_loss :0.9082101583480835\n",
            ".......... Batch 500/1096 d_loss1:0.17628853023052216 d_loss2 :0.0015715714544057846 g_loss :0.9408644437789917\n",
            ".......... Batch 600/1096 d_loss1:0.16312602162361145 d_loss2 :0.0007514560129493475 g_loss :0.8308823704719543\n",
            ".......... Batch 700/1096 d_loss1:0.1628994643688202 d_loss2 :0.0009651225409470499 g_loss :0.8203810453414917\n",
            ".......... Batch 800/1096 d_loss1:0.16310995817184448 d_loss2 :0.0023427940905094147 g_loss :0.8821499347686768\n",
            ".......... Batch 900/1096 d_loss1:0.16272230446338654 d_loss2 :0.0003439631254877895 g_loss :0.7977796196937561\n",
            ".......... Batch 1000/1096 d_loss1:0.16277572512626648 d_loss2 :6.13520314800553e-05 g_loss :0.8487513065338135\n",
            ".........Epoch: 25/100\n",
            ".......... Batch 100/1096 d_loss1:0.16299480199813843 d_loss2 :8.80384977790527e-05 g_loss :0.9389139413833618\n",
            ".......... Batch 200/1096 d_loss1:0.16271603107452393 d_loss2 :0.00011058945528930053 g_loss :0.9294687509536743\n",
            ".......... Batch 300/1096 d_loss1:0.16328056156635284 d_loss2 :0.00010513336019357666 g_loss :0.9775980710983276\n",
            ".......... Batch 400/1096 d_loss1:0.16266152262687683 d_loss2 :0.00012753818009514362 g_loss :1.1032130718231201\n",
            ".......... Batch 500/1096 d_loss1:0.16259779036045074 d_loss2 :9.879320714389905e-05 g_loss :0.884909987449646\n",
            ".......... Batch 600/1096 d_loss1:0.16263432800769806 d_loss2 :7.02035758877173e-05 g_loss :0.8886391520500183\n",
            ".......... Batch 700/1096 d_loss1:0.1625983566045761 d_loss2 :3.6252575227990746e-05 g_loss :0.9805785417556763\n",
            ".......... Batch 800/1096 d_loss1:0.16262808442115784 d_loss2 :2.707307976379525e-05 g_loss :0.8803419470787048\n",
            ".......... Batch 900/1096 d_loss1:0.16274699568748474 d_loss2 :2.3118882381822914e-05 g_loss :0.9279240369796753\n",
            ".......... Batch 1000/1096 d_loss1:0.16259773075580597 d_loss2 :2.453876004437916e-05 g_loss :0.9252773523330688\n",
            ".........Epoch: 26/100\n",
            ".......... Batch 100/1096 d_loss1:0.16275428235530853 d_loss2 :0.00011580040882108733 g_loss :0.9410995244979858\n",
            ".......... Batch 200/1096 d_loss1:0.16278839111328125 d_loss2 :4.169572639511898e-05 g_loss :0.8602127432823181\n",
            ".......... Batch 300/1096 d_loss1:0.1629159152507782 d_loss2 :2.429206870147027e-05 g_loss :1.1105808019638062\n",
            ".......... Batch 400/1096 d_loss1:0.1629898101091385 d_loss2 :3.627725527621806e-05 g_loss :1.023457407951355\n",
            ".......... Batch 500/1096 d_loss1:0.1628713607788086 d_loss2 :2.070592927339021e-05 g_loss :0.8646773099899292\n",
            ".......... Batch 600/1096 d_loss1:0.16282859444618225 d_loss2 :1.1978377187915612e-05 g_loss :0.8822225332260132\n",
            ".......... Batch 700/1096 d_loss1:0.1629316806793213 d_loss2 :1.6146299458341673e-05 g_loss :0.9986255168914795\n",
            ".......... Batch 800/1096 d_loss1:0.16305090487003326 d_loss2 :9.90906119113788e-06 g_loss :0.8812315464019775\n",
            ".......... Batch 900/1096 d_loss1:0.16317635774612427 d_loss2 :9.080903510039207e-06 g_loss :0.8313887715339661\n",
            ".......... Batch 1000/1096 d_loss1:0.16280971467494965 d_loss2 :7.566179647255922e-06 g_loss :0.8785303831100464\n",
            ".........Epoch: 27/100\n",
            ".......... Batch 100/1096 d_loss1:0.16276797652244568 d_loss2 :6.3863740251690615e-06 g_loss :0.856620192527771\n",
            ".......... Batch 200/1096 d_loss1:0.16304416954517365 d_loss2 :9.746765499585308e-06 g_loss :0.8910767436027527\n",
            ".......... Batch 300/1096 d_loss1:0.16259247064590454 d_loss2 :5.847258762514684e-06 g_loss :0.9417310953140259\n",
            ".......... Batch 400/1096 d_loss1:0.16280154883861542 d_loss2 :5.210135441302555e-06 g_loss :0.8544549942016602\n",
            ".......... Batch 500/1096 d_loss1:0.1627664417028427 d_loss2 :4.870800694334321e-06 g_loss :0.8607176542282104\n",
            ".......... Batch 600/1096 d_loss1:0.16291461884975433 d_loss2 :5.863542355655227e-06 g_loss :0.8875988721847534\n",
            ".......... Batch 700/1096 d_loss1:0.16273623704910278 d_loss2 :4.499723218032159e-06 g_loss :0.9018571376800537\n",
            ".......... Batch 800/1096 d_loss1:0.1627686321735382 d_loss2 :3.385443960723933e-06 g_loss :0.8713758587837219\n",
            ".......... Batch 900/1096 d_loss1:0.16256004571914673 d_loss2 :3.342177478771191e-06 g_loss :0.8243676424026489\n",
            ".......... Batch 1000/1096 d_loss1:0.1628568321466446 d_loss2 :3.564897724572802e-06 g_loss :0.958311915397644\n",
            ".........Epoch: 28/100\n",
            ".......... Batch 100/1096 d_loss1:0.1627229005098343 d_loss2 :3.260101493651746e-06 g_loss :0.8288111090660095\n",
            ".......... Batch 200/1096 d_loss1:0.16357475519180298 d_loss2 :2.751479541984736e-06 g_loss :1.0311349630355835\n",
            ".......... Batch 300/1096 d_loss1:0.16266313195228577 d_loss2 :6.206937086972175e-06 g_loss :0.9127280712127686\n",
            ".......... Batch 400/1096 d_loss1:0.16354431211948395 d_loss2 :1.056824839906767e-05 g_loss :0.8302671313285828\n",
            ".......... Batch 500/1096 d_loss1:0.16280631721019745 d_loss2 :0.00011271241965005174 g_loss :0.8824771642684937\n",
            ".......... Batch 600/1096 d_loss1:0.162820503115654 d_loss2 :3.939902398997219e-06 g_loss :0.8794389367103577\n",
            ".......... Batch 700/1096 d_loss1:0.16292709112167358 d_loss2 :6.855126684968127e-06 g_loss :0.8247530460357666\n",
            ".......... Batch 800/1096 d_loss1:0.16263413429260254 d_loss2 :7.1157141974254046e-06 g_loss :1.2005212306976318\n",
            ".......... Batch 900/1096 d_loss1:0.16293074190616608 d_loss2 :3.440140517341206e-06 g_loss :0.9319766759872437\n",
            ".......... Batch 1000/1096 d_loss1:0.16274188458919525 d_loss2 :4.103729224880226e-06 g_loss :0.8369853496551514\n",
            ".........Epoch: 29/100\n",
            ".......... Batch 100/1096 d_loss1:0.16277459263801575 d_loss2 :1.6213879234783235e-06 g_loss :1.0145483016967773\n",
            ".......... Batch 200/1096 d_loss1:0.16289126873016357 d_loss2 :2.804574023684836e-06 g_loss :0.8526512384414673\n",
            ".......... Batch 300/1096 d_loss1:0.16284102201461792 d_loss2 :3.843903868983034e-06 g_loss :0.8700598478317261\n",
            ".......... Batch 400/1096 d_loss1:0.1627444177865982 d_loss2 :4.775548859470291e-06 g_loss :0.8590152263641357\n",
            ".......... Batch 500/1096 d_loss1:0.1627252846956253 d_loss2 :0.00012771958427038044 g_loss :0.8932864665985107\n",
            ".......... Batch 600/1096 d_loss1:0.1630687266588211 d_loss2 :2.7811172458314104e-06 g_loss :1.0271234512329102\n",
            ".......... Batch 700/1096 d_loss1:0.16291290521621704 d_loss2 :6.865236628073035e-06 g_loss :0.8561325073242188\n",
            ".......... Batch 800/1096 d_loss1:0.1628452092409134 d_loss2 :1.5128662198549137e-06 g_loss :0.8794217109680176\n",
            ".......... Batch 900/1096 d_loss1:0.1629493683576584 d_loss2 :1.7639962379689678e-06 g_loss :0.7907103300094604\n",
            ".......... Batch 1000/1096 d_loss1:0.16270992159843445 d_loss2 :1.9788833469647216e-06 g_loss :1.0219945907592773\n",
            ".........Epoch: 30/100\n",
            ".......... Batch 100/1096 d_loss1:0.1628435105085373 d_loss2 :1.6536863540750346e-06 g_loss :0.9024816751480103\n",
            ".......... Batch 200/1096 d_loss1:0.16287551820278168 d_loss2 :8.918579510464042e-07 g_loss :0.9655786752700806\n",
            ".......... Batch 300/1096 d_loss1:0.162663534283638 d_loss2 :2.441058541080565e-06 g_loss :0.8401761054992676\n",
            ".......... Batch 400/1096 d_loss1:0.16266384720802307 d_loss2 :1.7336892597086262e-06 g_loss :0.8669339418411255\n",
            ".......... Batch 500/1096 d_loss1:0.16260837018489838 d_loss2 :2.053590833384078e-06 g_loss :1.0907058715820312\n",
            ".......... Batch 600/1096 d_loss1:0.16273997724056244 d_loss2 :2.2329950297717005e-06 g_loss :0.8752095699310303\n",
            ".......... Batch 700/1096 d_loss1:0.16277045011520386 d_loss2 :1.471380642215081e-06 g_loss :0.8417152166366577\n",
            ".......... Batch 800/1096 d_loss1:0.1631375402212143 d_loss2 :1.2092807537555927e-06 g_loss :0.8686449527740479\n",
            ".......... Batch 900/1096 d_loss1:0.1627340316772461 d_loss2 :2.124374304912635e-06 g_loss :0.7933554649353027\n",
            ".......... Batch 1000/1096 d_loss1:0.1626749038696289 d_loss2 :1.7663775224718847e-06 g_loss :0.8910791873931885\n",
            ".........WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            ">Saved: plot_30.png and model_30.h5\n",
            "Epoch: 31/100\n",
            ".......... Batch 100/1096 d_loss1:0.1627514362335205 d_loss2 :1.059108171830303e-06 g_loss :0.8970692753791809\n",
            ".......... Batch 200/1096 d_loss1:0.16270223259925842 d_loss2 :7.122128522496496e-07 g_loss :0.8857898712158203\n",
            ".......... Batch 300/1096 d_loss1:0.16278083622455597 d_loss2 :8.631765240352252e-07 g_loss :0.8275495767593384\n",
            ".......... Batch 400/1096 d_loss1:0.1627279818058014 d_loss2 :4.794218853021448e-07 g_loss :0.8464598655700684\n",
            ".......... Batch 500/1096 d_loss1:0.16313821077346802 d_loss2 :6.333735882435576e-07 g_loss :0.8963580131530762\n",
            ".......... Batch 600/1096 d_loss1:0.16281463205814362 d_loss2 :5.113922156851913e-07 g_loss :0.8978999853134155\n",
            ".......... Batch 700/1096 d_loss1:0.163050577044487 d_loss2 :1.585960853844881e-05 g_loss :0.8718183636665344\n",
            ".......... Batch 800/1096 d_loss1:0.16264799237251282 d_loss2 :1.7577811377122998e-05 g_loss :0.8845481872558594\n",
            ".......... Batch 900/1096 d_loss1:0.16291582584381104 d_loss2 :1.851064916991163e-05 g_loss :0.9781527519226074\n",
            ".......... Batch 1000/1096 d_loss1:0.16270364820957184 d_loss2 :3.4418131690472364e-05 g_loss :0.9659502506256104\n",
            ".........Epoch: 32/100\n",
            ".......... Batch 100/1096 d_loss1:0.1626317799091339 d_loss2 :3.356398519827053e-05 g_loss :0.9273301362991333\n",
            ".......... Batch 200/1096 d_loss1:0.1625547856092453 d_loss2 :9.039183169079479e-06 g_loss :0.9105426073074341\n",
            ".......... Batch 300/1096 d_loss1:0.16268548369407654 d_loss2 :7.131109214242315e-06 g_loss :0.8646618127822876\n",
            ".......... Batch 400/1096 d_loss1:0.16274358332157135 d_loss2 :1.464830529585015e-05 g_loss :0.8466951847076416\n",
            ".......... Batch 500/1096 d_loss1:0.16260316967964172 d_loss2 :2.1463520170073025e-05 g_loss :0.905940055847168\n",
            ".......... Batch 600/1096 d_loss1:0.16265207529067993 d_loss2 :1.0533589374972507e-05 g_loss :1.0069741010665894\n",
            ".......... Batch 700/1096 d_loss1:0.16263540089130402 d_loss2 :7.420254405587912e-05 g_loss :0.8146593570709229\n",
            ".......... Batch 800/1096 d_loss1:0.16259557008743286 d_loss2 :6.869732260383898e-06 g_loss :0.8726209402084351\n",
            ".......... Batch 900/1096 d_loss1:0.16273827850818634 d_loss2 :4.52161293651443e-06 g_loss :0.875999927520752\n",
            ".......... Batch 1000/1096 d_loss1:0.16277571022510529 d_loss2 :9.243519343726803e-06 g_loss :1.0312654972076416\n",
            ".........Epoch: 33/100\n",
            ".......... Batch 100/1096 d_loss1:0.16268381476402283 d_loss2 :4.949414687871467e-06 g_loss :0.8327406048774719\n",
            ".......... Batch 200/1096 d_loss1:0.1628302037715912 d_loss2 :5.80056939725182e-06 g_loss :0.8606835603713989\n",
            ".......... Batch 300/1096 d_loss1:0.1626589149236679 d_loss2 :0.00015338114462792873 g_loss :0.8813743591308594\n",
            ".......... Batch 400/1096 d_loss1:0.1631225049495697 d_loss2 :6.4749074226710945e-06 g_loss :0.8136782050132751\n",
            ".......... Batch 500/1096 d_loss1:0.16263419389724731 d_loss2 :1.8647049728315324e-05 g_loss :0.9465024471282959\n",
            ".......... Batch 600/1096 d_loss1:0.16270017623901367 d_loss2 :1.2480966688599437e-05 g_loss :0.8486514091491699\n",
            ".......... Batch 700/1096 d_loss1:0.16260264813899994 d_loss2 :1.085074200091185e-05 g_loss :0.972322940826416\n",
            ".......... Batch 800/1096 d_loss1:0.16266925632953644 d_loss2 :6.934709290362662e-06 g_loss :0.9889717102050781\n",
            ".......... Batch 900/1096 d_loss1:0.16263702511787415 d_loss2 :5.810352377011441e-06 g_loss :0.9413442015647888\n",
            ".......... Batch 1000/1096 d_loss1:0.162679523229599 d_loss2 :1.0112787094840314e-05 g_loss :0.9675495028495789\n",
            ".........Epoch: 34/100\n",
            ".......... Batch 100/1096 d_loss1:0.1625780165195465 d_loss2 :3.7959616747684777e-06 g_loss :0.9367623329162598\n",
            ".......... Batch 200/1096 d_loss1:0.16278915107250214 d_loss2 :3.4713075365289114e-06 g_loss :0.9410784244537354\n",
            ".......... Batch 300/1096 d_loss1:0.1627393662929535 d_loss2 :3.627540536399465e-06 g_loss :0.9280204176902771\n",
            ".......... Batch 400/1096 d_loss1:0.16280372440814972 d_loss2 :4.4521898416860495e-06 g_loss :1.0532090663909912\n",
            ".......... Batch 500/1096 d_loss1:0.16315089166164398 d_loss2 :4.327250280766748e-06 g_loss :0.9265658259391785\n",
            ".......... Batch 600/1096 d_loss1:0.16287223994731903 d_loss2 :1.8739276129053906e-05 g_loss :0.8814362287521362\n",
            ".......... Batch 700/1096 d_loss1:0.16270756721496582 d_loss2 :5.334206434781663e-06 g_loss :0.8731570243835449\n",
            ".......... Batch 800/1096 d_loss1:0.16266398131847382 d_loss2 :9.115790817304514e-06 g_loss :1.1578398942947388\n",
            ".......... Batch 900/1096 d_loss1:0.16272033751010895 d_loss2 :3.5418668176134815e-06 g_loss :0.8489176034927368\n",
            ".......... Batch 1000/1096 d_loss1:0.1627984493970871 d_loss2 :3.331549805807299e-06 g_loss :0.8766676187515259\n",
            ".........Epoch: 35/100\n",
            ".......... Batch 100/1096 d_loss1:0.16272886097431183 d_loss2 :1.6634488702038652e-06 g_loss :0.990506649017334\n",
            ".......... Batch 200/1096 d_loss1:0.1625940501689911 d_loss2 :2.326702087884769e-06 g_loss :0.962729275226593\n",
            ".......... Batch 300/1096 d_loss1:0.1627112627029419 d_loss2 :1.6296608009724878e-06 g_loss :0.929985523223877\n",
            ".......... Batch 400/1096 d_loss1:0.16283628344535828 d_loss2 :2.0421719000296434e-06 g_loss :0.9123432636260986\n",
            ".......... Batch 500/1096 d_loss1:0.16267690062522888 d_loss2 :1.5483832385143614e-06 g_loss :0.884351909160614\n",
            ".......... Batch 600/1096 d_loss1:0.16265934705734253 d_loss2 :1.661409100961464e-06 g_loss :0.8509007692337036\n",
            ".......... Batch 700/1096 d_loss1:0.16270151734352112 d_loss2 :1.55422037551034e-06 g_loss :0.8824880123138428\n",
            ".......... Batch 800/1096 d_loss1:0.16266945004463196 d_loss2 :1.7519455468573142e-06 g_loss :0.8697709441184998\n",
            ".......... Batch 900/1096 d_loss1:0.16274330019950867 d_loss2 :1.8959749468194786e-06 g_loss :0.8446654081344604\n",
            ".......... Batch 1000/1096 d_loss1:0.16285161674022675 d_loss2 :1.5507117723245756e-06 g_loss :0.9103604555130005\n",
            ".........Epoch: 36/100\n",
            ".......... Batch 100/1096 d_loss1:0.16271589696407318 d_loss2 :1.373735813103849e-06 g_loss :0.8383569121360779\n",
            ".......... Batch 200/1096 d_loss1:0.1628328114748001 d_loss2 :6.4630035012669396e-06 g_loss :0.8787537813186646\n",
            ".......... Batch 300/1096 d_loss1:0.16289566457271576 d_loss2 :1.8204457319370704e-06 g_loss :0.8222970962524414\n",
            ".......... Batch 400/1096 d_loss1:0.16272525489330292 d_loss2 :1.4517617046294617e-06 g_loss :0.919844388961792\n",
            ".......... Batch 500/1096 d_loss1:0.16261564195156097 d_loss2 :1.45779995364137e-06 g_loss :0.8679887056350708\n",
            ".......... Batch 600/1096 d_loss1:0.16272440552711487 d_loss2 :1.0459941677254392e-06 g_loss :0.9076002836227417\n",
            ".......... Batch 700/1096 d_loss1:0.16276460886001587 d_loss2 :1.1777647159760818e-06 g_loss :1.0106642246246338\n",
            ".......... Batch 800/1096 d_loss1:0.16274309158325195 d_loss2 :1.1280455964879366e-06 g_loss :0.8656843900680542\n",
            ".......... Batch 900/1096 d_loss1:0.16278567910194397 d_loss2 :9.956418125511846e-07 g_loss :0.8523584008216858\n",
            ".......... Batch 1000/1096 d_loss1:0.1628895401954651 d_loss2 :1.4396684946405003e-06 g_loss :0.8412927389144897\n",
            ".........Epoch: 37/100\n",
            ".......... Batch 100/1096 d_loss1:0.16279229521751404 d_loss2 :9.30658757170022e-07 g_loss :0.8288284540176392\n",
            ".......... Batch 200/1096 d_loss1:0.1626959890127182 d_loss2 :2.2908927803655388e-06 g_loss :0.9749928712844849\n",
            ".......... Batch 300/1096 d_loss1:0.16266778111457825 d_loss2 :2.549392775108572e-06 g_loss :0.8886958360671997\n",
            ".......... Batch 400/1096 d_loss1:0.162723571062088 d_loss2 :7.425014700856991e-07 g_loss :0.9119459390640259\n",
            ".......... Batch 500/1096 d_loss1:0.162824347615242 d_loss2 :8.604165486758575e-07 g_loss :0.934420645236969\n",
            ".......... Batch 600/1096 d_loss1:0.16265393793582916 d_loss2 :1.143445047091518e-06 g_loss :0.8384354114532471\n",
            ".......... Batch 700/1096 d_loss1:0.16284608840942383 d_loss2 :1.7669689214017126e-06 g_loss :0.8653902411460876\n",
            ".......... Batch 800/1096 d_loss1:0.16272950172424316 d_loss2 :2.2576698484044755e-06 g_loss :0.8198591470718384\n",
            ".......... Batch 900/1096 d_loss1:0.16279259324073792 d_loss2 :9.934349236573325e-07 g_loss :0.8268575668334961\n",
            ".......... Batch 1000/1096 d_loss1:0.16273781657218933 d_loss2 :1.0063112085845205e-06 g_loss :0.9456045627593994\n",
            ".........Epoch: 38/100\n",
            ".......... Batch 100/1096 d_loss1:0.16280251741409302 d_loss2 :8.124608257276122e-07 g_loss :0.8604884147644043\n",
            ".......... Batch 200/1096 d_loss1:0.16282562911510468 d_loss2 :7.750153372398927e-07 g_loss :0.8209689855575562\n",
            ".......... Batch 300/1096 d_loss1:0.16271021962165833 d_loss2 :7.329677487177833e-07 g_loss :0.8419897556304932\n",
            ".......... Batch 400/1096 d_loss1:0.16267213225364685 d_loss2 :7.101273808984843e-07 g_loss :0.8322618007659912\n",
            ".......... Batch 500/1096 d_loss1:0.16264724731445312 d_loss2 :6.778305419175013e-07 g_loss :0.7999150156974792\n",
            ".......... Batch 600/1096 d_loss1:0.16263890266418457 d_loss2 :7.247160169754352e-07 g_loss :0.8254693150520325\n",
            ".......... Batch 700/1096 d_loss1:0.1628120094537735 d_loss2 :9.190802074954263e-07 g_loss :0.8627208471298218\n",
            ".......... Batch 800/1096 d_loss1:0.16270118951797485 d_loss2 :8.191586289285624e-07 g_loss :0.8421590924263\n",
            ".......... Batch 900/1096 d_loss1:0.16273877024650574 d_loss2 :6.865865316285635e-07 g_loss :0.88762366771698\n",
            ".......... Batch 1000/1096 d_loss1:0.16271398961544037 d_loss2 :1.29871409626503e-06 g_loss :1.0885257720947266\n",
            ".........Epoch: 39/100\n",
            ".......... Batch 100/1096 d_loss1:0.16269519925117493 d_loss2 :8.615957654001249e-07 g_loss :0.8393749594688416\n",
            ".......... Batch 200/1096 d_loss1:0.16273058950901031 d_loss2 :6.610806622120435e-07 g_loss :0.8111351728439331\n",
            ".......... Batch 300/1096 d_loss1:0.16269859671592712 d_loss2 :7.990668677848589e-07 g_loss :0.841431736946106\n",
            ".......... Batch 400/1096 d_loss1:0.16276611387729645 d_loss2 :6.919162842677906e-07 g_loss :1.0686602592468262\n",
            ".......... Batch 500/1096 d_loss1:0.16256283223628998 d_loss2 :6.245362556001055e-07 g_loss :0.9149754643440247\n",
            ".......... Batch 600/1096 d_loss1:0.1626371294260025 d_loss2 :6.545626547449501e-07 g_loss :1.1254791021347046\n",
            ".......... Batch 700/1096 d_loss1:0.16269360482692719 d_loss2 :5.474388444781653e-07 g_loss :0.8446853160858154\n",
            ".......... Batch 800/1096 d_loss1:0.1626877635717392 d_loss2 :5.142558734405611e-07 g_loss :0.8343871831893921\n",
            ".......... Batch 900/1096 d_loss1:0.1626666635274887 d_loss2 :5.587732516687538e-07 g_loss :0.8603931665420532\n",
            ".......... Batch 1000/1096 d_loss1:0.16271454095840454 d_loss2 :4.871134251516196e-07 g_loss :0.870262086391449\n",
            ".........Epoch: 40/100\n",
            ".......... Batch 100/1096 d_loss1:0.16280554234981537 d_loss2 :6.002591703690996e-07 g_loss :0.9030316472053528\n",
            ".......... Batch 200/1096 d_loss1:0.1627109944820404 d_loss2 :6.412607831407513e-07 g_loss :0.8260587453842163\n",
            ".......... Batch 300/1096 d_loss1:0.1627296656370163 d_loss2 :6.253771402953134e-07 g_loss :0.897411584854126\n",
            ".......... Batch 400/1096 d_loss1:0.16264908015727997 d_loss2 :5.769913400399673e-07 g_loss :0.9134591817855835\n",
            ".......... Batch 500/1096 d_loss1:0.16264928877353668 d_loss2 :6.788783935007814e-07 g_loss :0.8327305316925049\n",
            ".......... Batch 600/1096 d_loss1:0.16279947757720947 d_loss2 :9.648765626479872e-07 g_loss :0.8295460939407349\n",
            ".......... Batch 700/1096 d_loss1:0.16271713376045227 d_loss2 :9.101449904846959e-07 g_loss :0.9205836057662964\n",
            ".......... Batch 800/1096 d_loss1:0.16275690495967865 d_loss2 :6.191961006152269e-07 g_loss :0.8188807964324951\n",
            ".......... Batch 900/1096 d_loss1:0.16264355182647705 d_loss2 :6.951434556867753e-07 g_loss :0.8270953893661499\n",
            ".......... Batch 1000/1096 d_loss1:0.16268575191497803 d_loss2 :6.193841386448184e-07 g_loss :0.8795900344848633\n",
            ".........WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            ">Saved: plot_40.png and model_40.h5\n",
            "Epoch: 41/100\n",
            ".......... Batch 100/1096 d_loss1:0.16273625195026398 d_loss2 :5.032237027080555e-07 g_loss :0.841780424118042\n",
            ".......... Batch 200/1096 d_loss1:0.16274955868721008 d_loss2 :5.324220069269359e-07 g_loss :0.8270798325538635\n",
            ".......... Batch 300/1096 d_loss1:0.1627635359764099 d_loss2 :6.874153086755541e-07 g_loss :0.9014531373977661\n",
            ".......... Batch 400/1096 d_loss1:0.16275271773338318 d_loss2 :4.914068654215953e-07 g_loss :0.895999550819397\n",
            ".......... Batch 500/1096 d_loss1:0.16286274790763855 d_loss2 :4.584352950587345e-07 g_loss :0.8823555111885071\n",
            ".......... Batch 600/1096 d_loss1:0.16265180706977844 d_loss2 :5.426512075246137e-07 g_loss :0.8930549621582031\n",
            ".......... Batch 700/1096 d_loss1:0.16267900168895721 d_loss2 :5.263839284452843e-07 g_loss :1.0520877838134766\n",
            ".......... Batch 800/1096 d_loss1:0.16267108917236328 d_loss2 :4.959740635968046e-07 g_loss :0.8558343648910522\n",
            ".......... Batch 900/1096 d_loss1:0.16265131533145905 d_loss2 :5.004533250030363e-07 g_loss :0.9406111240386963\n",
            ".......... Batch 1000/1096 d_loss1:0.16264216601848602 d_loss2 :4.942436362398439e-07 g_loss :0.8991659283638\n",
            ".........Epoch: 42/100\n",
            ".......... Batch 100/1096 d_loss1:0.1626644879579544 d_loss2 :4.5423914230013906e-07 g_loss :0.8956126570701599\n",
            ".......... Batch 200/1096 d_loss1:0.16275642812252045 d_loss2 :6.360196493915282e-07 g_loss :0.8429814577102661\n",
            ".......... Batch 300/1096 d_loss1:0.1626342087984085 d_loss2 :4.308052155010955e-07 g_loss :1.0186631679534912\n",
            ".......... Batch 400/1096 d_loss1:0.16271354258060455 d_loss2 :4.1615729173827276e-07 g_loss :0.8138242363929749\n",
            ".......... Batch 500/1096 d_loss1:0.1626943051815033 d_loss2 :5.793281161459163e-07 g_loss :0.8282039761543274\n",
            ".......... Batch 600/1096 d_loss1:0.16266779601573944 d_loss2 :7.920888833723438e-07 g_loss :0.7899208068847656\n",
            ".......... Batch 700/1096 d_loss1:0.16265463829040527 d_loss2 :4.757762326335069e-07 g_loss :0.9291976690292358\n",
            ".......... Batch 800/1096 d_loss1:0.16266122460365295 d_loss2 :4.2563110014270933e-07 g_loss :0.844117283821106\n",
            ".......... Batch 900/1096 d_loss1:0.1626565009355545 d_loss2 :4.4794396103498e-07 g_loss :0.8203901052474976\n",
            ".......... Batch 1000/1096 d_loss1:0.16266149282455444 d_loss2 :4.1452437926636776e-07 g_loss :0.8787752389907837\n",
            ".........Epoch: 43/100\n",
            ".......... Batch 100/1096 d_loss1:0.16263306140899658 d_loss2 :5.149925641489972e-07 g_loss :0.8712729215621948\n",
            ".......... Batch 200/1096 d_loss1:0.16271719336509705 d_loss2 :9.046141826729581e-07 g_loss :0.6996724605560303\n",
            ".......... Batch 300/1096 d_loss1:0.16268981993198395 d_loss2 :4.2516214193710766e-07 g_loss :0.8620332479476929\n",
            ".......... Batch 400/1096 d_loss1:0.1626817137002945 d_loss2 :6.125636105025478e-07 g_loss :0.8416270017623901\n",
            ".......... Batch 500/1096 d_loss1:0.16272269189357758 d_loss2 :5.134118623573158e-07 g_loss :0.8487861156463623\n",
            ".......... Batch 600/1096 d_loss1:0.16264992952346802 d_loss2 :4.6045059320931614e-07 g_loss :0.8489077091217041\n",
            ".......... Batch 700/1096 d_loss1:0.16276118159294128 d_loss2 :5.024746201343078e-07 g_loss :0.9352483749389648\n",
            ".......... Batch 800/1096 d_loss1:0.1626385599374771 d_loss2 :4.2505246256041573e-07 g_loss :1.0295770168304443\n",
            ".......... Batch 900/1096 d_loss1:0.16267289221286774 d_loss2 :4.5283391614248103e-07 g_loss :0.8407274484634399\n",
            ".......... Batch 1000/1096 d_loss1:0.16270971298217773 d_loss2 :7.374235337920254e-07 g_loss :0.8413697481155396\n",
            ".........Epoch: 44/100\n",
            ".......... Batch 100/1096 d_loss1:0.1626533716917038 d_loss2 :6.319439762592083e-07 g_loss :0.8684337139129639\n",
            ".......... Batch 200/1096 d_loss1:0.162671759724617 d_loss2 :9.641984206609777e-07 g_loss :0.944585919380188\n",
            ".......... Batch 300/1096 d_loss1:0.16267123818397522 d_loss2 :7.610294119331229e-07 g_loss :0.8780738115310669\n",
            ".......... Batch 400/1096 d_loss1:0.1627836376428604 d_loss2 :7.225044100778177e-07 g_loss :0.8776878118515015\n",
            ".......... Batch 500/1096 d_loss1:0.16263587772846222 d_loss2 :5.512293341780605e-07 g_loss :0.9407169818878174\n",
            ".......... Batch 600/1096 d_loss1:0.16274146735668182 d_loss2 :5.012499855183705e-07 g_loss :0.8428642749786377\n",
            ".......... Batch 700/1096 d_loss1:0.16275323927402496 d_loss2 :4.993451625523448e-07 g_loss :0.8484493494033813\n",
            ".......... Batch 800/1096 d_loss1:0.16270940005779266 d_loss2 :4.629843601833272e-07 g_loss :0.8205481767654419\n",
            ".......... Batch 900/1096 d_loss1:0.16267900168895721 d_loss2 :4.494917789088504e-07 g_loss :1.0773078203201294\n",
            ".......... Batch 1000/1096 d_loss1:0.1626470535993576 d_loss2 :4.758614124966698e-07 g_loss :0.7367095947265625\n",
            ".........Epoch: 45/100\n",
            ".......... Batch 100/1096 d_loss1:0.1627914309501648 d_loss2 :4.3720788767132035e-07 g_loss :0.8518432974815369\n",
            ".......... Batch 200/1096 d_loss1:0.16269023716449738 d_loss2 :5.735624881708645e-07 g_loss :1.0188755989074707\n",
            ".......... Batch 300/1096 d_loss1:0.1626567244529724 d_loss2 :4.836872449232033e-07 g_loss :0.9772157669067383\n",
            ".......... Batch 400/1096 d_loss1:0.1626954823732376 d_loss2 :4.194678240310168e-07 g_loss :0.959452748298645\n",
            ".......... Batch 500/1096 d_loss1:0.16271187365055084 d_loss2 :4.396163717501622e-07 g_loss :0.9503140449523926\n",
            ".......... Batch 600/1096 d_loss1:0.1626497209072113 d_loss2 :4.420444952302205e-07 g_loss :0.9476727247238159\n",
            ".......... Batch 700/1096 d_loss1:0.1626441329717636 d_loss2 :5.231232762525906e-07 g_loss :0.8483650088310242\n",
            ".......... Batch 800/1096 d_loss1:0.16264505684375763 d_loss2 :4.321494486703159e-07 g_loss :0.9062758684158325\n",
            ".......... Batch 900/1096 d_loss1:0.16265429556369781 d_loss2 :4.6304890588544367e-07 g_loss :0.8777796030044556\n",
            ".......... Batch 1000/1096 d_loss1:0.16271761059761047 d_loss2 :4.6429738631559303e-07 g_loss :0.8468658924102783\n",
            ".........Epoch: 46/100\n",
            ".......... Batch 100/1096 d_loss1:0.16268038749694824 d_loss2 :7.061498195071181e-07 g_loss :0.7273292541503906\n",
            ".......... Batch 200/1096 d_loss1:0.16267268359661102 d_loss2 :4.4985080194237526e-07 g_loss :0.8609087467193604\n",
            ".......... Batch 300/1096 d_loss1:0.16266480088233948 d_loss2 :5.632569468616566e-07 g_loss :1.171318531036377\n",
            ".......... Batch 400/1096 d_loss1:0.16263605654239655 d_loss2 :4.900437602373131e-07 g_loss :0.8599892854690552\n",
            "......"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMk33Lb3rEPz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}